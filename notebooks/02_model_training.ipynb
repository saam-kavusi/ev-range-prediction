{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-17T23:52:51.742430Z",
     "start_time": "2025-12-17T23:32:43.449070Z"
    }
   },
   "source": [
    "# ============================================================\n",
    "# 02_model_training.ipynb — Minimal Setup + Train/Evaluate Models\n",
    "# Goal: Train baseline + tree model using a leakage-safe Pipeline\n",
    "#       and evaluate with MAERMSE, R².\n",
    "#       (baseline + RF _ leakage _ error analysis)\n",
    "# ============================================================\n",
    "import warnings # supress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)  # numpy runtime warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)     # sklearn imputer warnings\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TARGET = \"range\"\n",
    "\n",
    "# ---- Load data ----\n",
    "df = pd.read_csv(\"../data/raw/vehicles.csv\", low_memory=False)\n",
    "df = df[df[\"fuelType1\"] == \"Electricity\"].copy() # EV only filter\n",
    "\n",
    "# dataset must be EV-only\n",
    "fuel_types = df[\"fuelType1\"].unique()\n",
    "assert len(fuel_types) == 1 and fuel_types[0] == \"Electricity\", (\n",
    "    f\"Sanity check failed: non-EV fuel types found: {fuel_types}\")\n",
    "\n",
    "\n",
    "# EVs should not exist before ~1997 (Check)\n",
    "assert df[\"year\"].min() >= 1997, (\n",
    "    f\"Sanity check failed: suspicious EV year detected: {df['year'].min()}\")\n",
    "df = df[df[\"year\"] >= 2011].copy()\n",
    "df = df.dropna(subset=[TARGET])\n",
    "print(\"Rows:\", df.shape[0], \"| Columns:\", df.shape[1])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Sanity checks: EV-only dataset validation\n",
    "# ------------------------------------------------------------\n",
    "# from IPython.display import display\n",
    "#print(\"EV year range:\", df[\"year\"].min(), \"→\", df[\"year\"].max())\n",
    "#print(\"Fuel types remaining:\", df[\"fuelType1\"].unique())\n",
    "#print(\"\\nEV counts by year (last 15 years shown):\")\n",
    "#display(df[\"year\"].value_counts().sort_index().tail(15))\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Build X/y\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET]\n",
    "\n",
    "# Group by vehicle identity\n",
    "GROUP_COLS = [\"make\", \"model\", \"year\"]  # if your column names differ, change here\n",
    "\n",
    "missing = [c for c in GROUP_COLS if c not in df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing grouping columns: {missing}. Run df.columns and update GROUP_COLS.\")\n",
    "\n",
    "groups = df[GROUP_COLS].astype(str).agg(\"_\".join, axis=1)\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_STATE)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n",
    "print(\"Unique groups - Train:\", groups.iloc[train_idx].nunique(), \"| Test:\", groups.iloc[test_idx].nunique())\n",
    "\n",
    "# Check to ensure no group overlap between train and test\n",
    "train_groups = set(groups.iloc[train_idx])\n",
    "test_groups = set(groups.iloc[test_idx])\n",
    "overlap = train_groups.intersection(test_groups)\n",
    "\n",
    "print(\"Group overlap count:\", len(overlap))\n",
    "assert len(overlap) == 0, \"Leakage: same make/model/year appears in both train and test.\"\n",
    "\n",
    "# ---- Column types ----\n",
    "num_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns\n",
    "\n",
    "# ---- Preprocessing ----\n",
    "numeric_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
    "\n",
    "categorical_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipe, num_cols),\n",
    "        (\"cat\", categorical_pipe, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\")\n",
    "\n",
    "print(\"Numeric cols:\", len(num_cols), \"| Categorical cols:\", len(cat_cols))\n",
    "# ---- Eval helper ----\n",
    "def eval_regression(name, y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(name)\n",
    "    print(f\"  MAE : {mae:.2f}\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(f\"  R^2 : {r2:.3f}\")\n",
    "    return {\"model\": name, \"mae\": mae, \"rmse\": rmse, \"r2\": r2}\n",
    "\n",
    "# ---- Models ----\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "# ---- Train + evaluate ----\n",
    "results = []\n",
    "pipes = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    pipes[model_name] = pipe   # <-- THIS creates pipes[\"Random Forest\"]\n",
    "    results.append(eval_regression(model_name, y_test, preds))\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"rmse\")\n",
    "results_df\n",
    "\n",
    "# Pull feature names after preprocessing (works with sklearn >= 1.0)\n",
    "feature_names = pipes[\"Random Forest\"] \\\n",
    "    .named_steps[\"preprocess\"] \\\n",
    "    .get_feature_names_out()\n",
    "\n",
    "rf_model = pipes[\"Random Forest\"].named_steps[\"model\"]\n",
    "\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "imp_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": importances\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "imp_df.head(30)\n",
    "\n",
    "# 1) Start with keyword-based suspects in ORIGINAL X columns\n",
    "suspect_patterns = [\n",
    "    \"range\", \"rng\", \"mile\", \"miles\",\n",
    "    \"mpge\", \"kwh\", \"kwh/100\", \"kwh_100\",\n",
    "    \"electric\", \"charge\", \"battery\", \"capacity\", \"fuelE\"\n",
    "]\n",
    "\n",
    "name_suspects = [c for c in X.columns if any(p in c.lower() for p in suspect_patterns)]\n",
    "\n",
    "# 2) Add ultra-high-correlation numeric suspects (ORIGINAL X columns)\n",
    "num_cols_all = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "corrs = X[num_cols_all].corrwith(y).abs().sort_values(ascending=False)\n",
    "corr_suspects = list(corrs[corrs > 0.98].index)\n",
    "\n",
    "to_drop = sorted(set(name_suspects + corr_suspects))\n",
    "\n",
    "print(f\"Dropping {len(to_drop)} suspect columns:\")\n",
    "print(to_drop[:80], \"...\" if len(to_drop) > 80 else \"\")\n",
    "\n",
    "# 3) Rebuild X/y with drops and rerun the exact same pipeline training\n",
    "X2 = df.drop(columns=[TARGET]).drop(columns=to_drop, errors=\"ignore\")\n",
    "y2 = df[TARGET]\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
    "    X2, y2, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "num_cols2 = X2_train.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "cat_cols2 = X2_train.select_dtypes(include=[\"object\", \"category\", \"bool\", \"string\"]).columns\n",
    "\n",
    "preprocess2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))]), num_cols2),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), cat_cols2)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "models2 = {\n",
    "    \"Linear Regression (no suspects)\": LinearRegression(),\n",
    "    \"Random Forest (no suspects)\": RandomForestRegressor(\n",
    "        n_estimators=300, random_state=RANDOM_STATE, n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "results2 = []\n",
    "for name, model in models2.items():\n",
    "    pipe = Pipeline([(\"preprocess\", preprocess2), (\"model\", model)])\n",
    "    pipe.fit(X2_train, y2_train)\n",
    "    preds = pipe.predict(X2_test)\n",
    "    results2.append(eval_regression(name, y2_test, preds))\n",
    "\n",
    "pd.DataFrame(results2).sort_values(\"rmse\")\n",
    "\n",
    "# Select the best-performing model from the previous evaluation\n",
    "BEST_MODEL_NAME = \"Random Forest (no suspects)\"\n",
    "\n",
    "# Rebuild and fit the pipeline on the training split\n",
    "best_pipe = Pipeline([\n",
    "    (\"preprocess\", preprocess2),\n",
    "    (\"model\", models2[BEST_MODEL_NAME])\n",
    "])\n",
    "best_pipe.fit(X2_train, y2_train)\n",
    "\n",
    "# Generate predictions on the test set\n",
    "preds = best_pipe.predict(X2_test)\n",
    "\n",
    "# Create a readable dataframe linking predictions to vehicle identity\n",
    "pred_df = X2_test[[\"make\", \"model\", \"year\"]].copy()\n",
    "pred_df[\"y_true\"] = y2_test.values\n",
    "pred_df[\"y_pred\"] = preds\n",
    "\n",
    "\n",
    "#-------------------------------------\n",
    "#         Error Analysis\n",
    "#------------------------------------\n",
    "# Absolute error highlights where the model performs worst\n",
    "pred_df[\"abs_error\"] = (pred_df[\"y_true\"] - pred_df[\"y_pred\"]).abs()\n",
    "\n",
    "# Display vehicles with the largest prediction errors\n",
    "pred_df.sort_values(\"abs_error\", ascending=False).head(20)\n",
    "\n",
    "# brand level summary\n",
    "brand_year_summary = (\n",
    "    pred_df\n",
    "    .groupby([\"make\", \"year\"])\n",
    "    .agg(\n",
    "        mean_abs_error=(\"abs_error\", \"mean\"),\n",
    "        median_abs_error=(\"abs_error\", \"median\"),\n",
    "        vehicle_count=(\"abs_error\", \"count\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Filter out unreliable brand-year groups (low sample size)\n",
    "brand_year_summary = brand_year_summary[\n",
    "    brand_year_summary[\"vehicle_count\"] >= 2]\n",
    "\n",
    "# Sort by typical (median) error\n",
    "brand_year_summary = brand_year_summary.sort_values(\n",
    "    \"median_abs_error\", ascending=False\n",
    ")\n",
    "\n",
    "brand_year_summary.head(15)\n",
    "\n",
    "# Provides a deeper breakdown to identify specific vehicle & Filtered to retain only reliable groups.\n",
    "model_error_summary = (\n",
    "    pred_df\n",
    "    .groupby([\"make\", \"model\"])\n",
    "    .agg(\n",
    "        min_year=(\"year\", \"min\"),\n",
    "        max_year=(\"year\", \"max\"),\n",
    "        mean_abs_error=(\"abs_error\", \"mean\"),\n",
    "        median_abs_error=(\"abs_error\", \"median\"),\n",
    "        vehicle_count=(\"abs_error\", \"count\"),\n",
    "    )\n",
    "    .sort_values(\"median_abs_error\", ascending=False)\n",
    ")\n",
    "\n",
    "model_error_summary[\"support_level\"] = np.where(\n",
    "    model_error_summary[\"vehicle_count\"] >= 2,\n",
    "    \"reliable\",\n",
    "    \"low_support\"\n",
    ")\n",
    "\n",
    "model_error_summary.head(15)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Resolve project paths\n",
    "PROJECT_ROOT = Path(\"..\")  # notebooks/ → project root\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save test-set prediction dataframe\n",
    "pred_df.to_csv(\n",
    "    DATA_PROCESSED / \"pred_df_test.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Save brand-year error summary\n",
    "brand_year_summary.to_csv(\n",
    "    DATA_PROCESSED / \"brand_year_error_summary.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Save model-level error summary\n",
    "model_error_summary.to_csv(\n",
    "    DATA_PROCESSED / \"model_error_summary.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"Saved processed artifacts to:\", DATA_PROCESSED.resolve())"
   ],
   "id": "511517c5dd34452c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# SAVE TRAINED MODEL + TEST DATA FOR INFERENCE\n",
    "# ============================================\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "MODELS_DIR = Path(\"../models\")\n",
    "DATA_PROCESSED = Path(\"../data/processed\")\n",
    "\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "dump(rf_model, MODELS_DIR / \"ev_range_model.joblib\")\n",
    "\n",
    "# Save test data\n",
    "X_test.to_csv(DATA_PROCESSED / \"X_test.csv\", index=False)\n",
    "y_test.to_csv(DATA_PROCESSED / \"y_test.csv\", index=False)\n",
    "\n",
    "print(\"Model and test data saved successfully.\")"
   ],
   "id": "478e35418dd33eb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# FINAL — Save full preprocessing + model Pipeline\n",
    "# Goal: Persist the *entire* sklearn Pipeline (preprocess + model)\n",
    "# so downstream inference never sees raw categorical strings.\n",
    "# ============================================\n",
    "\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure models directory exists\n",
    "Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save the FULL pipeline (not the bare estimator)\n",
    "joblib.dump(pipes[\"Random Forest\"], \"models/ev_range_model.joblib\")\n",
    "\n",
    "print(\"✅ Saved full Pipeline to models/ev_range_model.joblib\")\n",
    "print(\"Saved object type:\", type(pipes[\"Random Forest\"]))"
   ],
   "id": "de5dfa794ddaad81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# FINAL — Overwrite model artifact with FULL Pipeline (preprocess + model)\n",
    "# ============================================\n",
    "\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "MODEL_PATH = Path(\"models/ev_range_model.joblib\")\n",
    "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Confirm we actually have the pipeline in memory\n",
    "print(\"pipes keys:\", list(pipes.keys()))\n",
    "print(\"pipes['Random Forest'] type:\", type(pipes[\"Random Forest\"]))\n",
    "\n",
    "# 2) Hard check: this MUST be a sklearn Pipeline\n",
    "if not isinstance(pipes[\"Random Forest\"], Pipeline):\n",
    "    raise TypeError(\"pipes['Random Forest'] is not a sklearn Pipeline. Do NOT save.\")\n",
    "\n",
    "# 3) Overwrite the joblib with the full pipeline\n",
    "joblib.dump(pipes[\"Random Forest\"], MODEL_PATH)\n",
    "\n",
    "# 4) Verify what is actually saved on disk\n",
    "reloaded = joblib.load(MODEL_PATH)\n",
    "print(\"✅ Saved model artifact type on disk:\", type(reloaded))\n",
    "print(\"✅ Saved steps:\", reloaded.named_steps.keys())"
   ],
   "id": "4329581f230b2f3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# FINAL — Save FULL Pipeline to project-root /models\n",
    "# ============================================\n",
    "\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Notebook 02 runs from /notebooks, so project root is parent\n",
    "PROJECT_ROOT = Path.cwd() if (Path.cwd() / \"data\").exists() else Path.cwd().parent\n",
    "MODEL_PATH = PROJECT_ROOT / \"models\" / \"ev_range_model.joblib\"\n",
    "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"CWD:\", Path.cwd())\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"Saving to:\", MODEL_PATH)\n",
    "\n",
    "# Hard check: must be a Pipeline\n",
    "if not isinstance(pipes[\"Random Forest\"], Pipeline):\n",
    "    raise TypeError(\"pipes['Random Forest'] is not a sklearn Pipeline — do not save.\")\n",
    "\n",
    "joblib.dump(pipes[\"Random Forest\"], MODEL_PATH)\n",
    "\n",
    "# Verify what was actually written\n",
    "reloaded = joblib.load(MODEL_PATH)\n",
    "print(\"✅ On-disk type:\", type(reloaded))"
   ],
   "id": "4647ab8dba446e38",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
