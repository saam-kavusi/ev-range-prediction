{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-15T22:15:39.668759Z",
     "start_time": "2025-12-15T22:15:34.067485Z"
    }
   },
   "source": [
    "# ============================================================\n",
    "# 01_data_overview.ipynb â€” Load/Clean + Sanity Check EV Dataset\n",
    "# Goal: Load raw vehicle data, filter to EV-only rows, run quick sanity checks (fuel type/year/target),\n",
    "#       and produce a modeling-ready dataframe + (X, y) definitions for the training notebook.\n",
    "#      (validation + filtering)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd  # imports pandas lib with nickname pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# read the csv file with panda and save it into df(data frame)\n",
    "# .. means go up one in directory\n",
    "df = pd.read_csv(\"../data/raw/vehicles.csv\", low_memory=False)\n",
    "\n",
    "# pandas may raise DtypeWarnings when columns contain mixed data types\n",
    "# setting low_memory=False forces a full read and resolves the warning\n",
    "# this does not change the data, only how pandas parses it\n",
    "\n",
    "df.shape #check to make sure file loaded & dataset size (#rows,#col)\n",
    "\n",
    "# df.columns -> list of all column names | col = temp variable for the loop\n",
    "# loops through each column of list, converts to lower case for check\n",
    "# if keyword \"range\" if found returns og string and adds it to a list\n",
    "df = df.drop(columns=[\"rangeCityA\",\"rangeHwyA\",\"rangeA\"])\n",
    "[col for col in df.columns if \"range\" in col.lower()]\n",
    "\n",
    "# range = EPA combined electric range (primary target)\n",
    "# City/Highway = specific ranges\n",
    "# we have removed the alternative data info\n",
    "\n",
    "# (df[\"range\"] > 0)\n",
    "# .describe() - describes total value count, top = most true or false, frequency of top\n",
    "# .any() - true or false tell me if any of the columns containing keyword will have a value greater than 0?\n",
    "# .sum() - adds up all values that > 0 = # of EVs in dataset\n",
    "\n",
    "# X = clues | y = answer\n",
    "y = df[\"range\"]\n",
    "X = df.drop(columns=[\"range\"])\n",
    "# y stores target vector(labels)=EPA combined elec range for each EV\n",
    "# X contains the feature DataFrame(inputs). removes target column\n",
    "\n",
    "X.dtypes # shows data type for each column\n",
    "\n",
    "# drops not helpful predictors\n",
    "drop_cols = [\"createdOn\", \"modifiedOn\", \"mfrCode\", \"startStop\"]\n",
    "X = X.drop(columns=[c for c in drop_cols if c in X.columns])\n",
    "\n",
    "X.shape  # returns (rows, columns) for X\n",
    "X.head() # displays first 5 rows\n",
    "\n",
    "X.isna().sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "# identify columns\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns # numeric features\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"bool\"]).columns\n",
    "# catagorical/text features\n",
    "\n",
    "# compute % of missing values per column & drops those missing >40% of data\n",
    "missing_ratio = X.isna().mean()\n",
    "cols_to_drop = missing_ratio[missing_ratio > 0.4].index\n",
    "X = X.drop(columns=cols_to_drop)\n",
    "\n",
    "# replace missing numeric values with column median\n",
    "X[num_cols] = X[num_cols].fillna(X[num_cols].median())\n",
    "\n",
    "# keep only existing categorical columns (prevents KeyError)\n",
    "cat_cols = [c for c in cat_cols if c in X.columns]\n",
    "\n",
    "# replacing missing values with unknown\n",
    "X[cat_cols] = X[cat_cols].fillna(\"Unknown\")\n",
    "X.isna().sum().sum() # check to confrim no missing values reamin\n",
    "len(num_cols), len(cat_cols) # num of numeric and catagorial feature columns\n",
    "cat_cols # shows list of column\n",
    "\n",
    "\n",
    "# prevent leakage with train/test split\n",
    "X_train, X_test, y_train, y_test = (train_test_split\n",
    "(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    "))\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "# build preprocessing pipeline\n",
    "preprocess = (ColumnTransformer\n",
    "(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    "))\n",
    "# handle_unknown=\"ignore\" prevents crashes if test has a category not seen in train.\n",
    "# sparse_output=False makes it output a normal array\n",
    "\n",
    "# fit on train & transform train/test\n",
    "# fit_transform only on train | transform only on test\n",
    "X_train_model = preprocess.fit_transform(X_train)\n",
    "X_test_model = preprocess.transform(X_test)\n",
    "\n",
    "X_train_model.shape, X_test_model.shape\n",
    "\n",
    "\n",
    "# get final feature names\n",
    "feature_names = preprocess.get_feature_names_out()\n",
    "feature_names[:20], len(feature_names)\n",
    "\n",
    "# check to confirm train/test split sizes (rows, original feature columns)\n",
    "X_train.shape, X_test.shape\n",
    "# check after preprocessing/one-hot encoding, features expand to 7590 columns\n",
    "# (same column count in train/test = preprocessing pipeline is consistent)\n",
    "X_train_model.shape, X_test_model.shape\n",
    "# check numb of final feature columns after preprocessing\n",
    "# should match X_train_model.shape[1]\n",
    "len(feature_names)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7590"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
