{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-17T21:29:22.837119Z",
     "start_time": "2025-12-17T21:29:22.829139Z"
    }
   },
   "source": [
    "# ============================================================\n",
    "# 04_interpretation.ipynb — Interpret Results + Insights\n",
    "# Goal: Turn evaluation + error analysis into clear findings, limitations, and next steps for README/portfolio.\n",
    "# ============================================================"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T21:29:22.866465Z",
     "start_time": "2025-12-17T21:29:22.838244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------------------------------------------\n",
    "# Imports + project paths\n",
    "# --------------------------------------------\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\")  # notebooks/ -> project root\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "FIGURES_DIR = PROJECT_ROOT / \"figures\"\n",
    "\n",
    "# Inline sanity check (helps catch path issues early)\n",
    "print(\"DATA_PROCESSED:\", DATA_PROCESSED.resolve())\n",
    "print(\"FIGURES_DIR:\", FIGURES_DIR.resolve())"
   ],
   "id": "b5d3e6b555c3ea0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PROCESSED: /Users/saam/PycharmProjects/ev-range-prediction/data/processed\n",
      "FIGURES_DIR: /Users/saam/PycharmProjects/ev-range-prediction/figures\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T21:29:22.916700Z",
     "start_time": "2025-12-17T21:29:22.868760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------------------------------------------\n",
    "# Load artifacts produced in 03 (or earlier)\n",
    "# --------------------------------------------\n",
    "pred_path = DATA_PROCESSED / \"pred_df_test.csv\"\n",
    "worst_path = DATA_PROCESSED / \"worst_errors.csv\"\n",
    "\n",
    "pred_df = pd.read_csv(pred_path)\n",
    "worst_errors = pd.read_csv(worst_path)\n",
    "\n",
    "print(\"pred_df shape:\", pred_df.shape)\n",
    "print(\"worst_errors shape:\", worst_errors.shape)\n",
    "pred_df.head()"
   ],
   "id": "3e0a435fb3266993",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_df shape: (262, 6)\n",
      "worst_errors shape: (10, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      make                              model  year  y_true      y_pred  \\\n",
       "0      GMC              Hummer EV Pickup 2M20  2024     311  297.143333   \n",
       "1  Vinfast                          VF 8 Plus  2025     235  245.623333   \n",
       "2   Rivian  R1T Performance Dual Large (22in)  2024     341  341.333333   \n",
       "3   Toyota                               bZ4X  2024     252  246.756667   \n",
       "4   Rivian              R1S Quad Large (20in)  2024     289  291.833333   \n",
       "\n",
       "   abs_error  \n",
       "0  13.856667  \n",
       "1  10.623333  \n",
       "2   0.333333  \n",
       "3   5.243333  \n",
       "4   2.833333  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>abs_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GMC</td>\n",
       "      <td>Hummer EV Pickup 2M20</td>\n",
       "      <td>2024</td>\n",
       "      <td>311</td>\n",
       "      <td>297.143333</td>\n",
       "      <td>13.856667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vinfast</td>\n",
       "      <td>VF 8 Plus</td>\n",
       "      <td>2025</td>\n",
       "      <td>235</td>\n",
       "      <td>245.623333</td>\n",
       "      <td>10.623333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rivian</td>\n",
       "      <td>R1T Performance Dual Large (22in)</td>\n",
       "      <td>2024</td>\n",
       "      <td>341</td>\n",
       "      <td>341.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>bZ4X</td>\n",
       "      <td>2024</td>\n",
       "      <td>252</td>\n",
       "      <td>246.756667</td>\n",
       "      <td>5.243333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rivian</td>\n",
       "      <td>R1S Quad Large (20in)</td>\n",
       "      <td>2024</td>\n",
       "      <td>289</td>\n",
       "      <td>291.833333</td>\n",
       "      <td>2.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T21:29:22.982469Z",
     "start_time": "2025-12-17T21:29:22.938246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------------------------------------------\n",
    "# Compute key test metrics from pred_df\n",
    "# --------------------------------------------\n",
    "import numpy as np\n",
    "\n",
    "y_true = pred_df[\"y_true\"].to_numpy()\n",
    "y_pred = pred_df[\"y_pred\"].to_numpy()\n",
    "\n",
    "mae = np.mean(np.abs(y_true - y_pred))\n",
    "rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "# R^2 from definition (no sklearn needed)\n",
    "ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "summary = pd.DataFrame([{\n",
    "    \"MAE (miles)\": mae,\n",
    "    \"RMSE (miles)\": rmse,\n",
    "    \"R²\": r2\n",
    "}])\n",
    "\n",
    "summary"
   ],
   "id": "3bd5e33812c9999b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   MAE (miles)  RMSE (miles)        R²\n",
       "0    16.069504     23.320036  0.897312"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE (miles)</th>\n",
       "      <th>RMSE (miles)</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.069504</td>\n",
       "      <td>23.320036</td>\n",
       "      <td>0.897312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T21:29:23.020484Z",
     "start_time": "2025-12-17T21:29:22.984202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------------------------------------------\n",
    "# Interpretation notes\n",
    "# --------------------------------------------\n",
    "notes = [\n",
    "    f\"Test MAE is ~{mae:.1f} miles, meaning predictions are typically off by about that many miles.\",\n",
    "    f\"Test RMSE is ~{rmse:.1f} miles, which penalizes the largest misses more heavily than MAE.\",\n",
    "    f\"Test R² is ~{r2:.3f}, indicating how much variance in EV range the model explains on unseen data.\",\n",
    "    \"Error plots in /figures help identify where the model is strong vs weak (brands/years/outliers).\"\n",
    "]\n",
    "\n",
    "for n in notes:\n",
    "    print(\"- \" + n)"
   ],
   "id": "45aa318fed45b5fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Test MAE is ~16.1 miles, meaning predictions are typically off by about that many miles.\n",
      "- Test RMSE is ~23.3 miles, which penalizes the largest misses more heavily than MAE.\n",
      "- Test R² is ~0.897, indicating how much variance in EV range the model explains on unseen data.\n",
      "- Error plots in /figures help identify where the model is strong vs weak (brands/years/outliers).\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T21:29:23.057845Z",
     "start_time": "2025-12-17T21:29:23.024381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------------------------------------------\n",
    "# Reference saved figures (file names should exist in /figures)\n",
    "# --------------------------------------------\n",
    "figure_files = [\n",
    "    \"pred_vs_actual_test.png\",\n",
    "    \"abs_error_distribution.png\",\n",
    "    \"mae_by_brand.png\",\n",
    "    \"mae_by_year.png\",\n",
    "    \"mae_by_support_level.png\",\n",
    "]\n",
    "\n",
    "missing = [f for f in figure_files if not (FIGURES_DIR / f).exists()]\n",
    "print(\"Missing figures:\", missing)\n"
   ],
   "id": "6bc1d4b288a7e9dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing figures: []\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T21:29:23.153507Z",
     "start_time": "2025-12-17T21:29:23.078498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------------------------------------------\n",
    "# Export interpretation summary for README\n",
    "# --------------------------------------------\n",
    "out_md = DATA_PROCESSED / \"interpretation_summary.md\"\n",
    "\n",
    "md = f\"\"\"# EV Range Prediction — Interpretation Summary\n",
    "\n",
    "## Test-set performance\n",
    "- **MAE:** {mae:.2f} miles\n",
    "- **RMSE:** {rmse:.2f} miles\n",
    "- **R²:** {r2:.4f}\n",
    "\n",
    "## What the plots suggest\n",
    "- Predicted vs Actual: points close to the diagonal indicate good fit; outliers show worst misses.\n",
    "- Absolute error distribution: shows typical error and tail risk (rare large misses).\n",
    "- MAE by brand/year: highlights segments where the model generalizes poorly (often data scarcity or unusual models).\n",
    "\n",
    "## Limitations (important for credibility)\n",
    "- Some models/brands have low support → higher uncertainty.\n",
    "- EPA range can differ from real-world range; model predicts the dataset’s target definition.\n",
    "\n",
    "## Next steps\n",
    "- Add more features (battery kWh, weight, efficiency) if available.\n",
    "- Try a stronger model / tuning, or calibrate predictions for high-range vehicles.\n",
    "\"\"\"\n",
    "\n",
    "out_md.write_text(md, encoding=\"utf-8\")\n",
    "print(\"Saved:\", out_md.resolve())"
   ],
   "id": "d34bb2783d8c9d8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/saam/PycharmProjects/ev-range-prediction/data/processed/interpretation_summary.md\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
